Recovering the plan of traditional Chinese gardens has always been a difficult task. Although there are many surviving texts describing gardens, there are very few surviving garden plans, and researchers need to consume a lot of time to recover the layout of gardens based on the surviving texts.

We build the first dataset of Chinese gardens with text-image correspondence. We train a multimodal machine learning model, DALL-E, to generate semantic planes from textual descriptions of gardens. For these planes, we use grasshopperto generate 3D gardens. With this technology stream, garden researchers can easily reproduce a large number of classical Chinese gardens.
